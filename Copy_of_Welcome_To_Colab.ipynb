{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshu0027/10Days100DSA/blob/master/Copy_of_Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 1.1**"
      ],
      "metadata": {
        "id": "UEdsrD2UlRuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blank array\n",
        "import numpy as np\n",
        "print('IU2141230160')\n",
        "blank_array = np.zeros((3, 3))\n",
        "print(\"Blank Array:\")\n",
        "print(blank_array)\n",
        "\n",
        "import numpy as np\n",
        "print(\"IU2141230160\")\n",
        "predefined_array = np.array([1, 3, 5, 7, 9])\n",
        "print(\"Predefined Array:\")\n",
        "print(predefined_array)\n",
        "\n",
        "import numpy as np\n",
        "print(\"IU2141230160\")\n",
        "pattern_array = np.ones((3, 3))\n",
        "print(\"Pattern-specific Array:\")\n",
        "print(pattern_array)\n",
        "\n",
        "import numpy as np\n",
        "print(\"IU2141230160\")\n",
        "predefined_array = np.array([1, 3, 6, 7, 9])\n",
        "sliced_array = predefined_array[1:4]\n",
        "print(\"Sliced Array:\")\n",
        "print(sliced_array)\n",
        "predefined_array[2] = 10\n",
        "print(\"Updated Predefined Array:\")\n",
        "print(predefined_array)\n",
        "\n",
        "import numpy as np\n",
        "print(\"IU2141230160\")\n",
        "predefined_array = np.array([1, 3, 5, 6, 8])\n",
        "reshaped_array = np.reshape(predefined_array, (5, 1))\n",
        "print(\"Reshaped Array:\")\n",
        "print(reshaped_array)\n",
        "flattened_array = reshaped_array.flatten()\n",
        "print(\"Flattened Array:\")\n",
        "print(flattened_array)\n",
        "\n",
        "import numpy as np\n",
        "print(\"IU2141230160\")\n",
        "predefined_array = np.array([1, 3, 4, 6, 7])\n",
        "print(\"Looping Over Predefined Array:\")\n",
        "for element in predefined_array:\n",
        "  print(element)\n",
        "\n",
        "import numpy as np\n",
        "data = np.loadtxt('data.txt', delimiter=',')\n",
        "print(\"Data from file:\")\n",
        "print(data)"
      ],
      "metadata": {
        "id": "4Jar0YO8lUzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 1.2**"
      ],
      "metadata": {
        "id": "7nLRbQRUlZKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas\n",
        "import pandas as pd\n",
        "print(\"IU2141230160\")\n",
        "data = {\n",
        "'Name': ['AP', 'Kismat', 'Ansh'],\n",
        "'Age': [21, 22, 30],\n",
        "'City': ['New York', 'San Francisco', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n",
        "ages = df['Age']\n",
        "print(\"\\nAges:\")\n",
        "print(ages)\n",
        "filtered_df = df[df['Age'] > 28]\n",
        "print(\"\\nFiltered DataFrame (Age > 28):\")\n",
        "print(filtered_df)\n",
        "\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "x = [1, 3, 5, 7, 9]\n",
        "y = [2, 4, 5, 7, 11]\n",
        "plt.plot(x, y, marker='o')\n",
        "plt.title(\"Sample Plot\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UcO2X7N3lY1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 1.3**"
      ],
      "metadata": {
        "id": "JHPcgIjjlhbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "from scipy import stats, interpolate\n",
        "import numpy as np\n",
        "\n",
        "print(\"IU2141230160\")\n",
        "\n",
        "def rosen(x):\n",
        "    return sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
        "\n",
        "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
        "\n",
        "res = minimize(rosen, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True})\n",
        "print(\"Optimized parameters:\", res.x)\n",
        "\n",
        "data = np.array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
        "\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data)\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Standard Deviation:\", std_dev)\n",
        "\n",
        "t_stat, p_value = stats.ttest_1samp(data, 5)\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "x = np.linspace(0, 10, 10)\n",
        "y = np.sin(x)\n",
        "f_interp = interpolate.interp1d(x, y, kind='linear')\n",
        "x_new = 2.5\n",
        "y_new = f_interp(x_new)\n",
        "print(f\"Interpolated value at x={x_new}: {y_new}\")"
      ],
      "metadata": {
        "id": "maUrMrGJljUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 1.4**"
      ],
      "metadata": {
        "id": "m02hKtvHlldO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"IU2141230160\")\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
      ],
      "metadata": {
        "id": "8aeByByGloFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find S Algorithm**"
      ],
      "metadata": {
        "id": "sa269gdUlwhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"IU2141230160 - Anshu Patel\\n\")\n",
        "\n",
        "data = pd.read_csv(\"traindata.csv\")\n",
        "print(\"Dataset:\\n\", data, \"\\n\")\n",
        "\n",
        "attributes = np.array(data)[:, :-1]\n",
        "print(\"Attributes:\\n\", attributes)\n",
        "\n",
        "target = np.array(data)[:, -1]\n",
        "print(\"Target:\\n\", target)\n",
        "\n",
        "def train(attributes, target):\n",
        "    specific_hypothesis = None\n",
        "\n",
        "    for i, val in enumerate(target):\n",
        "        if val == \"Yes\":\n",
        "            specific_hypothesis = attributes[i].copy()\n",
        "            break\n",
        "\n",
        "    if specific_hypothesis is not None:\n",
        "        for i, val in enumerate(attributes):\n",
        "            if target[i] == \"Yes\":\n",
        "                for x in range(len(specific_hypothesis)):\n",
        "                    if val[x] != specific_hypothesis[x]:\n",
        "                        specific_hypothesis[x] = '?'\n",
        "    return specific_hypothesis\n",
        "\n",
        "final_hypothesis = train(attributes, target)\n",
        "print(\"\\nFinal hypothesis:\\n\", final_hypothesis)"
      ],
      "metadata": {
        "id": "euAi34Bsl42r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Regression**"
      ],
      "metadata": {
        "id": "hk7PauoCl7Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "print(\"IU2141230160 - Anshu Patel\")\n",
        "\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "df = data.frame\n",
        "\n",
        "df = df.sample(n=200, random_state=42)\n",
        "\n",
        "X = df[['MedInc']]\n",
        "y = df['MedHouseVal']\n",
        "\n",
        "print(f\"Total observations in data: {df.shape[0]}\")\n",
        "print(f\"Number of independent variables: {X.shape[1]}\")\n",
        "print(f\"Dependent variable: {y.name}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "sse = np.sum((y_test - y_pred) ** 2)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'SSE: {sse:.2f}')\n",
        "print(f'RÂ² Score: {r2:.2f}')\n",
        "\n",
        "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
        "plt.plot(X_test, y_pred, color='red', label='Predicted')\n",
        "plt.title('Simple Linear Regression')\n",
        "plt.xlabel('Median Income')\n",
        "plt.ylabel('Median House Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mtq7i2gNl-F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi Linear Regression**"
      ],
      "metadata": {
        "id": "NKlumbcPmKXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"IU2141230160 - Anshu Patel\")\n",
        "\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "df = data.frame\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "X = df[['MedInc', 'HouseAge', 'AveRooms']]\n",
        "y = df['MedHouseVal']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "area = 3000\n",
        "bedrooms = 4\n",
        "age = 15\n",
        "\n",
        "new_data = pd.DataFrame([[area, age, bedrooms]], columns=['MedInc', 'HouseAge', 'AveRooms'])  # Adjust column names\n",
        "predicted_price = model.predict(new_data)\n",
        "\n",
        "print(f'Predicted Price: {predicted_price[0]}')"
      ],
      "metadata": {
        "id": "jMUg9bdkmPZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "4qdzDWW6mRcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "print(\"Total observations in data:\", df.shape[0])\n",
        "\n",
        "X, y = df.drop(columns=['target']), df['target']\n",
        "\n",
        "print(\"Number of independent variables:\", X.shape[1])\n",
        "print(\"Dependent variable:\", y.name)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
        "\n",
        "print(\"Steps taken for improvement:\")\n",
        "print(\"1. Feature Engineering: Create additional relevant features.\")\n",
        "print(\"2. Hyperparameter Tuning: Use Grid Search or Random Search for optimal hyperparameters.\")\n",
        "print(\"3. Model Selection: Compare with algorithms like SVM, Random Forest, or Gradient Boosting.\")\n",
        "print(\"4. Class Imbalance: Use oversampling, undersampling, or cost-sensitive learning.\")\n",
        "print(\"5. Cross-Validation: Implement k-fold cross-validation for better generalization.\")\n",
        "\n",
        "def predict_cancer(features):\n",
        "    features_df = pd.DataFrame([features], columns=X.columns)\n",
        "    return \"Malignant\" if logreg.predict(features_df)[0] == 1 else \"Benign\"\n",
        "\n",
        "features = X_test.iloc[0]\n",
        "print(\"Prediction for the first test sample features:\", predict_cancer(features))"
      ],
      "metadata": {
        "id": "9d8_SQFImg_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree**"
      ],
      "metadata": {
        "id": "V6EDCSvTmmyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_tree(clf, filled=True, rounded=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "plt.show()\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(f\"Average Score: {scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "j2PU2L1dmo_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Mean Cluster**"
      ],
      "metadata": {
        "id": "3xqvokLemxS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "n_samples = 500\n",
        "n_features = 2\n",
        "n_clusters = 5\n",
        "\n",
        "X, _ = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=42)\n",
        "\n",
        "data = pd.DataFrame(X, columns=['Annual Income (k$)', 'Spending Score (1-100)'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(data)\n",
        "\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(features_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "optimal_clusters = 5\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(features_scaled)\n",
        "\n",
        "labels = kmeans.predict(features_scaled)\n",
        "data['Cluster'] = labels\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(features_scaled[:, 0], features_scaled[:, 1], c=labels, cmap='viridis', label='Clusters')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', label='Centroids')\n",
        "plt.title('K-means Clustering')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "H3KnEyZOm0ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Algorithm**"
      ],
      "metadata": {
        "id": "1Lv-WXn4m7K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
        "\n",
        "df = pd.DataFrame(X, columns=['Age', 'EstimatedSalary'])\n",
        "df['Purchased'] = y\n",
        "\n",
        "X = df[['Age', 'EstimatedSalary']]\n",
        "y = df['Purchased']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'\\nClassification Report:')\n",
        "print(report)\n",
        "\n",
        "plt.scatter(X['Age'], X['EstimatedSalary'], c=y, cmap='viridis')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.title('Scatterplot of Age vs Estimated Salary')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(X['Age'], bins=20, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Age')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(X['EstimatedSalary'], bins=20, color='salmon', edgecolor='black')\n",
        "plt.xlabel('Estimated Salary')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Estimated Salary')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "26drJ9gGm-Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayesian **"
      ],
      "metadata": {
        "id": "dEuKKdH7nM8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "data = pd.read_csv('sample_data.csv')\n",
        "\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "classifier = GaussianNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "szPdGJx7nQdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OR and AND**"
      ],
      "metadata": {
        "id": "IhmQlSDPnQJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, epochs=10):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def activation_function(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                linear_output = np.dot(X[i], self.weights) + self.bias\n",
        "                y_pred = self.activation_function(linear_output)\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.learning_rate * error * X[i]\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for i in range(X.shape[0]):\n",
        "            linear_output = np.dot(X[i], self.weights) + self.bias\n",
        "            y_pred.append(self.activation_function(linear_output))\n",
        "        return np.array(y_pred)\n",
        "\n",
        "X_OR = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_OR = np.array([0, 1, 1, 1])\n",
        "\n",
        "X_AND = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_AND = np.array([0, 0, 0, 1])\n",
        "\n",
        "perceptron_OR = Perceptron(learning_rate=0.1, epochs=10)\n",
        "perceptron_AND = Perceptron(learning_rate=0.1, epochs=10)\n",
        "\n",
        "print(\"Training OR gate\")\n",
        "perceptron_OR.fit(X_OR, y_OR)\n",
        "\n",
        "predictions_OR = perceptron_OR.predict(X_OR)\n",
        "print(\"Predictions for OR gate:\")\n",
        "for i, prediction in enumerate(predictions_OR):\n",
        "    print(f\"Input: {X_OR[i]}, Prediction: {prediction}, Actual: {y_OR[i]}\")\n",
        "\n",
        "print(\"\\nTraining AND gate\")\n",
        "perceptron_AND.fit(X_AND, y_AND)\n",
        "\n",
        "predictions_AND = perceptron_AND.predict(X_AND)\n",
        "print(\"Predictions for AND gate:\")\n",
        "for i, prediction in enumerate(predictions_AND):\n",
        "    print(f\"Input: {X_AND[i]}, Prediction: {prediction}, Actual: {y_AND[i]}\")"
      ],
      "metadata": {
        "id": "TdQ1qztZnaFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Back Propagation**"
      ],
      "metadata": {
        "id": "n88nW3Zhn9Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.5):\n",
        "        self.weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))\n",
        "        self.weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))\n",
        "        self.bias_hidden = np.random.uniform(size=(1, hidden_size))\n",
        "        self.bias_output = np.random.uniform(size=(1, output_size))\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "\n",
        "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.final_output = sigmoid(self.final_input)\n",
        "\n",
        "        return self.final_output\n",
        "\n",
        "    def backpropagation(self, X, y, output):\n",
        "        output_error = y - output\n",
        "        output_delta = output_error * sigmoid_derivative(output)\n",
        "\n",
        "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * self.learning_rate\n",
        "        self.weights_input_hidden += X.T.dot(hidden_delta) * self.learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.feedforward(X)\n",
        "\n",
        "            self.backpropagation(X, y, output)\n",
        "\n",
        "            if (epoch + 1) % 1000 == 0:\n",
        "                loss = np.mean(np.square(y - output))\n",
        "                print(f\"Epoch {epoch + 1}, Loss: {loss:.5f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.feedforward(X)\n",
        "        return np.round(output)\n",
        "\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=2, output_size=1)\n",
        "\n",
        "nn.train(X, y, epochs=10000)\n",
        "\n",
        "print(\"\\nPredictions after training:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"Input: {X[i]}, Predicted Output: {nn.predict(X[i].reshape(1, -1))}, Actual Output: {y[i]}\")"
      ],
      "metadata": {
        "id": "5Zml2GjRoC0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}